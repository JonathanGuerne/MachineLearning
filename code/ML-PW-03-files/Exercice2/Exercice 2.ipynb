{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2\n",
    "\n",
    "**auteurs : Costa Pedro, Delabays Louis, Guerne Jonathan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to remove the ; at the end of every line to make it work\n",
    "data_a = np.loadtxt('ex2-system-a.csv', delimiter=';')\n",
    "\n",
    "dta_prior = data_a[:,:-1]\n",
    "dta_y = data_a[:,-1].astype(int)\n",
    "nb_class_a = len(np.unique(dta_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes pour la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(data_prior):\n",
    "    return np.array([np.argmax(data_prior[i,:]) for i in range(len(data_prior))])\n",
    "\n",
    "preds_a = get_preds(dta_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de overall error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall error rate : 0.10729999999999995\n"
     ]
    }
   ],
   "source": [
    "def ovrl_error(data_y,preds):\n",
    "    ovrl_acc = len(data_y[data_y == preds])/len(data_y)\n",
    "    return 1-ovrl_acc\n",
    "\n",
    "er_a = ovrl_error(dta_y,preds_a)\n",
    "print(\"Overall error rate : {}\".format(er_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calcul de la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.440e+02 0.000e+00 1.100e+01 0.000e+00 0.000e+00 2.000e+00 1.000e+01\n",
      "  7.000e+00 5.000e+00 1.000e+00]\n",
      " [0.000e+00 1.112e+03 2.000e+00 3.000e+00 1.000e+00 4.000e+00 3.000e+00\n",
      "  1.000e+00 9.000e+00 0.000e+00]\n",
      " [1.000e+01 6.000e+00 9.210e+02 1.200e+01 1.500e+01 3.000e+00 1.900e+01\n",
      "  1.500e+01 2.600e+01 5.000e+00]\n",
      " [1.000e+00 1.000e+00 3.100e+01 8.620e+02 2.000e+00 7.200e+01 5.000e+00\n",
      "  1.400e+01 1.200e+01 1.000e+01]\n",
      " [2.000e+00 3.000e+00 6.000e+00 2.000e+00 9.100e+02 1.000e+00 1.200e+01\n",
      "  6.000e+00 4.000e+00 3.600e+01]\n",
      " [1.200e+01 3.000e+00 6.000e+00 2.900e+01 1.900e+01 7.680e+02 1.900e+01\n",
      "  9.000e+00 2.100e+01 6.000e+00]\n",
      " [1.400e+01 3.000e+00 2.100e+01 2.000e+00 2.200e+01 2.800e+01 8.650e+02\n",
      "  0.000e+00 3.000e+00 0.000e+00]\n",
      " [0.000e+00 1.400e+01 3.000e+01 9.000e+00 7.000e+00 2.000e+00 1.000e+00\n",
      "  9.290e+02 3.000e+00 3.300e+01]\n",
      " [1.200e+01 1.600e+01 1.800e+01 2.600e+01 2.400e+01 4.600e+01 2.200e+01\n",
      "  1.900e+01 7.720e+02 1.900e+01]\n",
      " [1.000e+01 4.000e+00 6.000e+00 2.200e+01 5.300e+01 1.800e+01 0.000e+00\n",
      "  4.800e+01 4.000e+00 8.440e+02]]\n"
     ]
    }
   ],
   "source": [
    "def get_confusion_matrix(data_y, preds,nb_class):\n",
    "    confusion_matrix = np.ndarray((nb_class,nb_class))\n",
    "\n",
    "    for i in np.unique(data_y):\n",
    "        row = np.bincount(preds[data_y == i], minlength=nb_class)\n",
    "        confusion_matrix[i] = row\n",
    "    return confusion_matrix\n",
    "\n",
    "cma = get_confusion_matrix(dta_y,preds_a,nb_class_a)\n",
    "print(cma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calcul du recall et de la précision de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_and_precision(confusion_matrix, nb_class):\n",
    "    tp_all = [confusion_matrix[i,i] for i in range(nb_class)]\n",
    "    fn_all = [sum(confusion_matrix[i,:]) - tp_all[i] for i in range(nb_class)]\n",
    "    fp_all = [sum(confusion_matrix[:,i]) - tp_all[i] for i in range(nb_class)]\n",
    "\n",
    "    recall_all = [tp_all[i]/(tp_all[i] + fn_all[i]) for i in range(nb_class)]\n",
    "    precision_all = [tp_all[i]/(tp_all[i] + fp_all[i]) for i in range(nb_class)]\n",
    "    \n",
    "    return recall_all,precision_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sélection des meilleurs et pires classes en fonction du recall et de la précision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pire classes :\n",
      "Recall : 1\n",
      "Precision : 1\n",
      "Meilleure classes :\n",
      "Recall : 8\n",
      "Precision : 5\n"
     ]
    }
   ],
   "source": [
    "recall_all, precision_all = get_recall_and_precision(cma,nb_class_a)\n",
    "\n",
    "print(\"Pire classes :\")\n",
    "\n",
    "print(\"Recall : {}\".format(np.argsort(recall_all)[-1]))\n",
    "print(\"Precision : {}\".format(np.argsort(precision_all)[-1]))\n",
    "\n",
    "print(\"Meilleure classes :\")\n",
    "\n",
    "print(\"Recall : {}\".format(np.argsort(recall_all)[0]))\n",
    "print(\"Precision : {}\".format(np.argsort(precision_all)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calcul du F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.8907308492877297\n"
     ]
    }
   ],
   "source": [
    "def get_f1_score(recall_all,precision_all,nb_class):\n",
    "    f1_all = [2 * (precision_all[i]*recall_all[i])/\n",
    "              (precision_all[i] + recall_all[i])\n",
    "             for i in range(nb_class)]\n",
    "\n",
    "    return np.mean(f1_all)\n",
    "\n",
    "f1_a = get_f1_score(recall_all,precision_all,nb_class_a)\n",
    "print(\"f1 score : {}\".format(f1_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = np.loadtxt('ex2-system-b.csv', delimiter=';')\n",
    "\n",
    "dtb_prior = data_b[:,:-1]\n",
    "dtb_y = data_b[:,-1].astype(int)\n",
    "nb_class_b = len(np.unique(dtb_y))\n",
    "\n",
    "preds_b = get_preds(dtb_prior)\n",
    "\n",
    "er_b = ovrl_error(dtb_y,preds_b)\n",
    "\n",
    "cmb = get_confusion_matrix(dtb_y,preds_b,nb_class_b)\n",
    "\n",
    "recall_all, precision_all = get_recall_and_precision(cmb, nb_class_b)\n",
    "\n",
    "f1_b = get_f1_score(recall_all,precision_all,nb_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison des systemes :\n",
      "Systeme A :\n",
      "\toverall error rate : 0.10729999999999995\n",
      "\tf1 score : 0.8907308492877297\n",
      "Systeme B :\n",
      "\toverall error rate : 0.03869999999999996\n",
      "\tf1 score : 0.9608568150389065\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparaison des systemes :\")\n",
    "print(\"Systeme A :\")\n",
    "print(\"\\toverall error rate : {}\".format(er_a))\n",
    "print(\"\\tf1 score : {}\".format(f1_a))\n",
    "print(\"Systeme B :\")\n",
    "print(\"\\toverall error rate : {}\".format(er_b))\n",
    "print(\"\\tf1 score : {}\".format(f1_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à ces deux mesures on peut en conclure que le système B est un meilleur classifieur que le système A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
